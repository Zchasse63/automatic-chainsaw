# Research Output: custom_research
## Generated: 2026-02-13T15:38:28.047047
## Preset: advanced-deep-research
## Model: anthropic/claude-opus-4-6
## Cost: $0.4757
## Research steps: 5 searches, 4 URL fetches
## Output length: 118 chars, 20 words

---

Now I have the Together AI serverless LoRA supported base models. Let me get Nebius details and check other platforms.

---

## Sources

- [Overview - Fireworks AI Docsdocs.fireworks.ai › models › overview](https://docs.fireworks.ai/models/overview)
- [Fine-tuning - Supported Models - Together.ai Docs](https://docs.together.ai/docs/fine-tuning-models)
- [Fine-tune open models with Nebius Token Factory](https://nebius.com/services/token-factory/fine-tuning)
- [Supervised Fine-Tuning (SFT) with LoRA on Fireworks AI](https://fireworks.ai/blog/supervised-fine-tuning-tutorial)
- [Announcing Serverless Multi-LoRA: Fine-tune and deploy hundreds ...](https://www.together.ai/blog/serverless-multi-lora-fine-tune-and-deploy-hundreds-of-adapters-for-model-customization-at-scale)
- [How to fine-tune your custom model](https://docs.studio.nebius.com/fine-tuning/how-to-fine-tune)
- [Fireworks AI - Fast Inference Platform - Kodus](https://docs.kodus.io/cookbook/en/fireworks)
- [Supported Models - Together.ai Docs](https://togetherai-52386018.mintlify.app/docs/fine-tuning-models)
- [How to Fine-Tune Open Source LLMs with Nebius Token Factory | Full Tutorial](https://www.youtube.com/watch?v=gqCZ_sFha7E)
- [Concepts - Fireworks AI Docs - Introduction](https://fireworksai-docs.mintlify.app/getting-started/concepts)
- [Serverless Models - Together.ai Docs](https://togetherai-52386018.mintlify.app/docs/serverless-models)
- [Takeoff Serverless LoRA: Efficient inference at scale for ...](https://www.doubleword.ai/resources/takeoff-serverless-lora-efficient-inference-at-scale-for-fine-tuned-models)
- [Does FLUX support image-to-image generation?](https://fireworksai-docs.mintlify.app/faq-new/models-inference/flux-image-generation)
- [Together Fine-Tuning: Continuously Customize and Optimize Models](https://www.youtube.com/watch?v=JJSFtci3lEU)
- [Make AI work for you: fine-tuning launches on Nebius AI Studio](https://www.youtube.com/watch?v=wk04TOCsFuw)
- [Pricing - Together AI](https://www.together.ai/pricing)
- [Audio models](https://docs.together.ai/docs/serverless-models)
- [Together AI | The AI Native Cloud](https://www.together.ai)
- [Supervised Fine Tuning on Fireworks AI](https://www.youtube.com/watch?v=FpRd6eFmjjs)
- [Together AI Review 2025: Pricing, Features & Alternatives](https://www.rankncompare.com/tools/together-ai)
- [Together AI API Pricing and Rate Limits](https://hassandevops.site/together-ai-api-pricing-and-rate-limits-1)
- [Together.ai provider - AI SDK](https://ai-sdk.dev/providers/ai-sdk-providers/togetherai)
- [Fireworks AI](https://docs.litellm.ai/docs/providers/fireworks_ai)
- [What is Together AI? Features, Pricing, and Use Cases - Walturn](https://www.walturn.com/insights/what-is-together-ai-features-pricing-and-use-cases)
- [Serverless LoRA Inference](https://docs.together.ai/docs/lora-inference)
- [Combine LoRAs when...](https://replicate.com/docs/guides/extend/working-with-loras)
- [Create a LoRA Playground with Modal, Gradio, and S3](https://modal.com/docs/examples/cloud_bucket_mount_loras)
- [You can now fine-tune open-source video models – Replicate blog](https://replicate.com/blog/fine-tune-video)
- [Products - Inference - Modal](https://modal.com/products/inference)
- [How To Train a LoRa on Replicate](https://www.youtube.com/watch?v=QSgC7Db84ZM)
- [Using LoRA adapters - Modular Docs](https://docs.modular.com/max/serve/lora-adapters/)
- [Fine Tune a Flux model with Replicate.com - Generate any image with your face on it](https://www.youtube.com/watch?v=EWZN4vU1E1M)
- [Building a Stable Diffusion + LoRA image generation pipeline on Modal](https://www.youtube.com/watch?v=sHSKArbiKmU)
- [lora-training/README.md at main · replicate/lora-training](https://github.com/replicate/lora-training/blob/main/README.md)
- [llm-finetuning/README.md at main · modal-labs/llm-finetuning](https://github.com/modal-labs/llm-finetuning/blob/main/README.md)
- [](https://docs.together.ai/docs/lora-adapter-upload)
- [Pricing - Fireworks AI](https://fireworks.ai/pricing)
- [Fine-tuning in Nebius AI Studio: Overview](https://docs.studio.nebius.com/fine-tuning/overview)
- [Fireworks: Models Intelligence, Performance & Price](https://artificialanalysis.ai/providers/fireworks)
- [Fireworks AI: Features, and Pricing](https://www.eesel.ai/blog/fireworks-ai-pricing)
- [Cost structure - Fireworks AI Docs](https://fireworks.ai/docs/faq/billing-pricing-usage/pricing/cost-structure)
- [Nebius. The ultimate cloud for AI explorers](https://preprod.nebius.ai)
- [What is Fireworks AI? Features, Pricing, and Use Cases](https://www.walturn.com/insights/what-is-fireworks-ai-features-pricing-and-use-cases)
- [Nebius AI Studio Q1 2025 roundup: Fine-tuning, new models and major expansions](https://preprod.nebius.ai/blog/posts/q1-2025-studio-updates)
- [](https://docs.together.ai/docs/lora-supported-models)
- [Evaluations Supported Models](https://docs.together.ai/docs/evaluations-supported-models)
- [Overview - Fireworks AI Docs](https://docs.fireworks.ai/models/overview)
- [Step 4: Running LoRA inference](https://docs.together.ai/docs/lora-training-and-inference)
- [Upload a LoRA Adapter - Together.ai Docs](https://docs.together.ai/docs/adapter-upload)
- [Fine-tuning Guide - Together.ai Docs](https://docs.together.ai/docs/fine-tuning-quickstart)
- [How to check if a model is available on serverless? - Fireworks AI ...](https://fireworksai-docs.mintlify.app/faq-new/models-inference/how-to-check-if-a-model-is-available-on-serverless)
- [Changelog](https://docs.together.ai/docs/changelog)
- [Together.AI เปิดบริการ Serverless LoRA ไม่คิดค่าโฮสต์โมเดลที่ปรับแต่งแล้ว คิดแต่ค่ารันตามโทเค็น](https://www.blognone.com/node/143814)
- [Deploying a Fine-tuned Model - Together.ai Docs](https://docs.together.ai/docs/deploying-a-fine-tuned-model)
- [Does anyone know which (if any) serverless providers ...](https://news.ycombinator.com/item?id=40139694)

---

## Original Prompt

```
I need to find the best open-source LLM models that support BOTH LoRA fine-tuning AND serverless LoRA inference (serving fine-tuned adapters without dedicated GPU deployment) in 2026. Research the following platforms comprehensively:

1. **Fireworks AI** — Which models support serverless LoRA inference? Check their docs, blog posts, and model catalog. Specifically: can LoRA adapters for any model >70B be served serverlessly?

2. **Together AI** — Which models support serverless LoRA inference? Check their serverless multi-LoRA announcement and supported models list. What's the largest model that supports serverless LoRA?

3. **Nebius AI** — Do they offer LoRA fine-tuning and serverless LoRA inference? What models?

4. **Modal** — Do they support LoRA serving? What models?

5. **Replicate** — Do they support fine-tuning + LoRA serving? What models?

6. **Any other platforms** (Anyscale/Aviary, Lepton AI, Baseten, OctoAI, RunPod, etc.) that offer serverless LoRA fine-tuning + inference.

For each platform, I need:
- Exact list of models that support BOTH fine-tuning AND serverless LoRA inference
- Maximum model size that supports serverless LoRA
- Pricing for fine-tuning (per token or per GPU-hour)
- Pricing for serverless inference (per token)
- Whether they support the chat completions format (OpenAI-compatible)
- Any relevant limitations

I'm specifically looking for models with strong reasoning/instruction-following capabilities in the 70B+ range. Key candidates to check:
- Llama 3.1 70B/405B Instruct
- Llama 4 models (Maverick, Scout)
- DeepSeek R1 / DeepSeek V3
- Qwen 3 models (235B, 32B)
- Kimi K2 Thinking / K2 Instruct
- Mistral Large / Mixtral
- Any MoE models that might work

The use case: I fine-tuned a LoRA on Kimi K2 Thinking via Fireworks AI but discovered K2 doesn't support serverless LoRA serving (needs 32 H100s for on-demand). I need to find an alternative base model + platform where I can fine-tune AND serve the LoRA serverlessly at reasonable cost. I have 729 training examples in JSONL chat completions format.
```
